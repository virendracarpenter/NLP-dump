{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
      "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
      "Collecting de-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.5.0/de_core_news_sm-3.5.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m436.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from de-core-news-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (66.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cis/Documents/Projects/NLP/.venv/lib/python3.11/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.1.3)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -mspacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'We use the QR code image as the initial image and the control image, which allows you to generate QR Codes that blend in very naturally with your provided prompt. The strength parameter defines how much noise is added to your QR code and the noisy QR code is then guided towards both your prompt and the QR code image via Controlnet. Use a high strength value between 0.8 and 0.95 and choose a conditioning scale between 0.6 and 2.0. This mode arguably achieves the asthetically most appealing QR code images, but also requires more tuning of the controlnet conditioning scale and the strength value. If the generated image looks way to much like the original QR code, make sure to gently increase the strength value and reduce the conditioning scale.'\n",
    "\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
    "for token in doc:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('like twee two is a number by name $')\n",
    "# token0 = doc[1]\n",
    "# token0.is_digit\n",
    "# token0.like_num\n",
    "# token0.text\n",
    "# token0 = doc[-2]\n",
    "# token0.is_currency\n",
    "doc[1].like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('students.txt', mode='r') as f:\n",
    "    text = f.readlines()\n",
    "text = ' '.join(text)\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "emails = [token.text for token in doc if token.like_email]\n",
    "emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'eat',\n",
       " 'ice',\n",
       " 'cream',\n",
       " '.',\n",
       " 'i',\n",
       " 'love',\n",
       " 'eating',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'in',\n",
       " 'summers',\n",
       " '.',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Icecream',\n",
       " 'is',\n",
       " 'most',\n",
       " 'famous']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case('wanna',[\n",
    "    {ORTH: 'wan'},\n",
    "    {ORTH: 'na'}\n",
    "])\n",
    "\n",
    "doc = nlp('i wanna eat ice cream. i love eating ice cream in summers. Mr. Icecream is most famous')\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sents \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m doc\u001b[39m.\u001b[39;49msents]\n",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sents \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents]\n",
      "File \u001b[0;32m~/Documents/Projects/NLP/.venv/lib/python3.11/site-packages/spacy/tokens/doc.pyx:888\u001b[0m, in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "sents = [s for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'sentencizer' already exists in pipeline. Existing names: ['sentencizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nlp\u001b[39m.\u001b[39;49madd_pipe(\u001b[39m'\u001b[39;49m\u001b[39msentencizer\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Projects/NLP/.venv/lib/python3.11/site-packages/spacy/language.py:775\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    773\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m factory_name\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE007\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, opts\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names))\n\u001b[1;32m    776\u001b[0m \u001b[39m# Overriding pipe name in the config is not supported and will be ignored.\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n",
      "\u001b[0;31mValueError\u001b[0m: [E007] 'sentencizer' already exists in pipeline. Existing names: ['sentencizer']"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wanna eat ice cream.\n",
      "i love eating ice cream in summers.\n",
      "Mr.\n",
      "Icecream is most famous\n"
     ]
    }
   ],
   "source": [
    "for s in doc.sents: print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
